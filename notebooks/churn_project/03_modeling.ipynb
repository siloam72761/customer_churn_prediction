{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d05e3b8-cb29-48c0-b01f-ccf7325f3a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import joblib\n",
    "\n",
    "#전처리된 데이터 불러오기\n",
    "pd.set_option(\"display.max_rows\", 10)\n",
    "customer_churn_reviews = pd.read_csv(\"../../data/customer_churn_preprocessed.csv\", index_col = 0)\n",
    "\n",
    "#데이터셋 분리\n",
    "X = customer_churn_reviews.drop('Churn', axis = 1)\n",
    "y = customer_churn_reviews['Churn']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32925684-ed4a-4c08-a358-895ff332ddc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Accuracy: 0.8055358410220014\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.89      0.87      1035\n",
      "           1       0.66      0.56      0.60       374\n",
      "\n",
      "    accuracy                           0.81      1409\n",
      "   macro avg       0.75      0.73      0.74      1409\n",
      "weighted avg       0.80      0.81      0.80      1409\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 로지스틱 회귀 : 이진 분류 baseline\n",
    "\n",
    "#1. 로지스틱 회귀\n",
    "log_reg = LogisticRegression(max_iter = 1000)\n",
    "log_reg.fit(X_train, y_train)\n",
    "y_pred_lr = log_reg.predict(X_test)\n",
    "\n",
    "print(\"Logistic Regression\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_lr))\n",
    "print(classification_report(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e80d3b37-4477-4135-9e07-1f27641a06a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest\n",
      "Accuracy: 0.7849538679914834\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.89      0.86      1035\n",
      "           1       0.62      0.51      0.56       374\n",
      "\n",
      "    accuracy                           0.78      1409\n",
      "   macro avg       0.72      0.70      0.71      1409\n",
      "weighted avg       0.77      0.78      0.78      1409\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 랜덤포레스트 : 비선형 관계 잘 잡음\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "print(\"\\nRandom Forest\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "085c6404-569c-45f1-8032-39ba8bc8457d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Logistic Regression ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.849     0.895     0.871      1035\n",
      "           1      0.657     0.559     0.604       374\n",
      "\n",
      "    accuracy                          0.806      1409\n",
      "   macro avg      0.753     0.727     0.738      1409\n",
      "weighted avg      0.798     0.806     0.800      1409\n",
      "\n",
      "Confusion matrix:\n",
      " [[926 109]\n",
      " [165 209]]\n",
      "ROC-AUC: 0.8421116536206051\n",
      "\n",
      "=== Random Forest ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.832     0.886     0.858      1035\n",
      "           1      0.616     0.505     0.555       374\n",
      "\n",
      "    accuracy                          0.785      1409\n",
      "   macro avg      0.724     0.696     0.707      1409\n",
      "weighted avg      0.775     0.785     0.778      1409\n",
      "\n",
      "Confusion matrix:\n",
      " [[917 118]\n",
      " [185 189]]\n",
      "ROC-AUC: 0.8186016171949676\n"
     ]
    }
   ],
   "source": [
    "#두 모델 recall(1) 부분을 살펴보면 이탈 고객 중 절반 정도 밖에 못 잡고 있음\n",
    "#이 부분을 개선하기 위해 데이터 불균형 처리\n",
    "#좀 더 자세히 알아보기 위해 Confusion Matrix, ROC-AUC 지표 추가\n",
    "\n",
    "# 해결책\n",
    "# Oversampling (Smote) : 이탈 고객 데이터를 synthetic하게 늘림\n",
    "# Undersampling : 비이탈 고객 일부 줄임\n",
    "# Class weights 조정 : 모델이 이탈 고객을 더 중요하게 보도록 가중치 설정\n",
    "\n",
    "# ── Logistic Regression ─────────────────────────────────────────\n",
    "print(\"\\n=== Logistic Regression ===\")\n",
    "print(classification_report(y_test, y_pred_lr, digits=3))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred_lr))\n",
    "lr_proba = log_reg.predict_proba(X_test)[:, 1]\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, lr_proba))\n",
    "\n",
    "# ── Random Forest ──────────────────────────────────────────────\n",
    "print(\"\\n=== Random Forest ===\")\n",
    "print(classification_report(y_test, y_pred_rf, digits=3))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred_rf))\n",
    "rf_proba = rf.predict_proba(X_test)[:, 1]\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, rf_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d2c3591f-2cb0-4fd8-9cb2-21f8d51d5561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Logistic Regression (class_weight=balanced) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.902     0.721     0.801      1035\n",
      "           1      0.503     0.783     0.613       374\n",
      "\n",
      "    accuracy                          0.737      1409\n",
      "   macro avg      0.703     0.752     0.707      1409\n",
      "weighted avg      0.796     0.737     0.751      1409\n",
      "\n",
      "Confusion matrix:\n",
      " [[746 289]\n",
      " [ 81 293]]\n",
      "ROC-AUC: 0.8416543956185901\n"
     ]
    }
   ],
   "source": [
    "#Confusion Matrix에서 FN비율을 줄이는 방향으로 설계\n",
    "#class weight 조정하기\n",
    "\n",
    "#Logistic Regression with class_weight\n",
    "log_reg = LogisticRegression(max_iter=1000, class_weight=\"balanced\")\n",
    "log_reg.fit(X_train, y_train)\n",
    "y_pred_lr = log_reg.predict(X_test)\n",
    "\n",
    "print(\"\\n=== Logistic Regression (class_weight=balanced) ===\")\n",
    "print(classification_report(y_test, y_pred_lr, digits=3))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred_lr))\n",
    "lg_proba = log_reg.predict_proba(X_test)[:, 1]\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, lg_proba))\n",
    "\n",
    "#실행 결과 FN 185 -> 81, 다만 FP가 증가하게 됌."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fad6a338-21a3-4098-8f4c-110eb2f08ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Random Forest (class_weight=balanced) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.827     0.885     0.855      1035\n",
      "           1      0.606     0.489     0.541       374\n",
      "\n",
      "    accuracy                          0.780      1409\n",
      "   macro avg      0.717     0.687     0.698      1409\n",
      "weighted avg      0.769     0.780     0.772      1409\n",
      "\n",
      "Confusion matrix:\n",
      " [[916 119]\n",
      " [191 183]]\n",
      "ROC-AUC: 0.8186481180087317\n"
     ]
    }
   ],
   "source": [
    "# Random Forest with class_weight\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42, class_weight=\"balanced\")\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "print(\"\\n=== Random Forest (class_weight=balanced) ===\")\n",
    "print(classification_report(y_test, y_pred_rf, digits=3))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred_rf))\n",
    "rf_proba = rf.predict_proba(X_test)[:, 1]\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, rf_proba))\n",
    "\n",
    "#실행 결과 FN이 줄어들지않고, 오히려 조금 증가함. (조정이 필요)\n",
    "#RandomForest는 다수 트리의 투표 기반이기에, 클래스 1에 가중치를 줘도\n",
    "#Threshold(0.5)는 그대로라서 오히려 증가할 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dc096229-d570-4631-90d3-8854b2384a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Random Forest (adjust Threshold ) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.851     0.834     0.842      1035\n",
      "           1      0.565     0.596     0.580       374\n",
      "\n",
      "    accuracy                          0.771      1409\n",
      "   macro avg      0.708     0.715     0.711      1409\n",
      "weighted avg      0.775     0.771     0.773      1409\n",
      "\n",
      "Confusion matrix:\n",
      " [[863 172]\n",
      " [151 223]]\n",
      "ROC-AUC: 0.8186481180087317\n"
     ]
    }
   ],
   "source": [
    "#Randeom Forest 개선 방향 : Threshold 조정\n",
    "\n",
    "y_proba = rf.predict_proba(X_test)[:,1]\n",
    "y_pred_custom = (y_proba >= 0.4).astype(int) #Threshold 낮추기\n",
    "\n",
    "print(\"\\n=== Random Forest (adjust Threshold ) ===\")\n",
    "print(classification_report(y_test, y_pred_custom, digits=3))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred_custom))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_proba))\n",
    "\n",
    "#FN이 191->151로 유의미하게 감소.\n",
    "#하지만 Threshold 0.4는 임의의 값이다.\n",
    "#최적의 Threshold를 찾기 위해 \"Precision-Recall Curve 기반\" 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b986d146-8fdd-4ba1-ba89-34deba8c1f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Random Forest (Best Threshold ) ===\n",
      "Best Threshold :  0.25 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.895     0.726     0.801      1035\n",
      "           1      0.502     0.765     0.606       374\n",
      "\n",
      "    accuracy                          0.736      1409\n",
      "   macro avg      0.698     0.745     0.704      1409\n",
      "weighted avg      0.791     0.736     0.750      1409\n",
      "\n",
      "Confusion matrix:\n",
      " [[751 284]\n",
      " [ 88 286]]\n",
      "ROC-AUC: 0.8186481180087317\n"
     ]
    }
   ],
   "source": [
    "#최적의 Threshold 찾기 (Precision-Recall Curve)\n",
    "\n",
    "prec, rec, thresholds = precision_recall_curve(y_test, y_proba)\n",
    "\n",
    "#F1 계산\n",
    "f1_scores = 2 * (prec * rec) / (prec + rec)\n",
    "best_idx = f1_scores.argmax()\n",
    "best_threshold_f1 = thresholds[best_idx]\n",
    "\n",
    "# 최적 threshold 적용\n",
    "print(\"\\n=== Random Forest (Best Threshold ) ===\")\n",
    "print(\"Best Threshold : \", best_threshold_f1 , \"\\n\" )\n",
    "y_pred_f1 = (y_proba >= best_threshold_f1).astype(int)\n",
    "print(classification_report(y_test, y_pred_f1, digits=3))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred_f1))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_proba))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "23c32c25-a030-4426-9cd2-15dae92e8d69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../results/final_lg_model.pkl']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RF 실행결과 : FN이 165->81로 감소\n",
    "#LG 실행결과 : FN이 191->88로 감소\n",
    "\n",
    "#최종적으로 두 모델의 성능이 거의 비슷함.\n",
    "#중점은 \"이탈 고객을 최대한 놓치지 않겠다\" 이기 때문에 FN이 더 낮은 \"Logistic Regression\" 선택\n",
    "\n",
    "#최종 선택한 모델 저장\n",
    "joblib.dump(log_reg, \"../../results/final_lg_model.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
